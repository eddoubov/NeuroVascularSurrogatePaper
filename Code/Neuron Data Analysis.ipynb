{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard data science libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math\n",
    "import copy as cp\n",
    "import time\n",
    "\n",
    "plt.close('all')\n",
    "sns.set(color_codes=True)\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy.optimize import minimize, least_squares\n",
    "\n",
    "from sklearn.linear_model import Lasso, LinearRegression\n",
    "\n",
    "import scipy.stats as st\n",
    "from scipy import signal\n",
    "import scipy\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.fftpack import fft, ifft, rfft, irfft\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import itertools\n",
    "from itertools import permutations\n",
    "\n",
    "import sys\n",
    "\n",
    "import pyunicorn\n",
    "from pyunicorn import timeseries\n",
    "from pyunicorn.timeseries.surrogates import Surrogates\n",
    "\n",
    "from matplotlib import cm\n",
    "\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import NeuronVasomotionFunc as nvf\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-reporter",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cutting-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLagMat(X, tau_list):\n",
    "    X = np.array(X)\n",
    "    num_tau = len(tau_list)\n",
    "    start_ind = np.max(tau_list)\n",
    "    num_rows_X = X.shape[0]\n",
    "    num_rows_lag = num_rows_X - start_ind\n",
    "    \n",
    "    lag_X_matrix = np.zeros((num_rows_lag, num_tau))\n",
    "\n",
    "    for i in np.arange(num_tau):        \n",
    "        temp_tau = tau_list[i]\n",
    "        \n",
    "        lag_X_matrix[:,i] = X[(start_ind-temp_tau):(num_rows_X-temp_tau)]\n",
    "    \n",
    "    return lag_X_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-consultation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CMA_Sync(X, N, eig_values, eig_vecs, alpha, smooth):    \n",
    "    m = len(eig_values);\n",
    "    #print(m)\n",
    "    lambda_mat_surr = np.zeros((N, len(eig_values)))\n",
    "\n",
    "    ts = timeseries.surrogates.Surrogates(X.T, silence_level=2)\n",
    "    for i in np.arange(N):\n",
    "        #surr_ts = ts.refined_AAFT_surrogates(X, n_iterations=5)\n",
    "        surr_ts = ts.AAFT_surrogates(X.T)\n",
    "        surr_ts = surr_ts.T\n",
    "        \n",
    "        if smooth[0] == 1:\n",
    "            surr_ts = smooth_mat(surr_ts, smooth[1])\n",
    "        \n",
    "        surr_cov_mat = np.cov(surr_ts.T)\n",
    "        surr_eig_values, surr_eig_vecs = np.linalg.eig(surr_cov_mat);\n",
    "    \n",
    "        temp_sort_ind = np.argsort(surr_eig_values)\n",
    "        sorted_surr_eig_values = surr_eig_values[temp_sort_ind]\n",
    "    \n",
    "        lambda_mat_surr[i,:] = sorted_surr_eig_values\n",
    "    \n",
    "    mean_lambdas_surr = np.mean(lambda_mat_surr, axis=0)\n",
    "    std_lambdas_surr = np.std(lambda_mat_surr, axis=0)\n",
    "\n",
    "    K = st.norm.ppf(1-alpha/2)\n",
    "    \n",
    "    thresh = K*std_lambdas_surr\n",
    "    \n",
    "    sync_ind = np.zeros(m)\n",
    "    for t in np.arange(m):\n",
    "        if eig_values[t] > (thresh[t] + mean_lambdas_surr[t]):\n",
    "            sync_ind[t] = (eig_values[t] - mean_lambdas_surr[t])/(m - mean_lambdas_surr[t])\n",
    "        else:\n",
    "            sync_ind[t] = 0\n",
    "    \n",
    "    PI_mat = np.zeros((m,m))\n",
    "\n",
    "    for i in np.arange(m):\n",
    "        PI_mat[m-i-1,:] = eig_values[i]*(np.power(eig_vecs[:,i], 2))\n",
    "    \n",
    "    return [sync_ind, PI_mat, mean_lambdas_surr, thresh]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-climate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTimeWindows(data, T, w):\n",
    "    \n",
    "    data = np.array(data);\n",
    "    \n",
    "    if len(data.shape) > 1:\n",
    "        num_dim = data.shape[1];\n",
    "    else:\n",
    "        num_dim = 1;\n",
    "        data = data.reshape((len(data),1))\n",
    "        \n",
    "    num_obs = data.shape[0];\n",
    "    \n",
    "    ref_beg_ind = 0;\n",
    "    \n",
    "    static_init_mat = np.zeros((T,num_dim,1))\n",
    "    \n",
    "    T_vec = []\n",
    "    \n",
    "    while ref_beg_ind < num_obs-T:\n",
    "        \n",
    "        if ref_beg_ind == 0:\n",
    "            tw_mat = static_init_mat;\n",
    "        else:\n",
    "            tw_mat = np.concatenate((tw_mat, static_init_mat), axis=2);\n",
    "        \n",
    "        ref_end_ind = ref_beg_ind + T;\n",
    "        \n",
    "        #print(ref_end_ind)\n",
    "        \n",
    "        tw_mat[:,:,-1] = data[ref_beg_ind:ref_end_ind,:];\n",
    "        \n",
    "        ref_beg_ind = ref_end_ind - w;\n",
    "    \n",
    "        T_vec.append(ref_end_ind)\n",
    "    \n",
    "    return [tw_mat, np.array(T_vec)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-galaxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detCorrSigTimeLags(X, L, tau_list):\n",
    "    L_strd = (L - np.mean(L))/np.std(L)\n",
    "\n",
    "    lag_X_matrix = createLagMat(X, tau_list)\n",
    "    \n",
    "    max_tau_shift = np.max(tau_list)\n",
    "    \n",
    "    L_temp = L_strd[max_tau_shift:]\n",
    "    \n",
    "    corr_vec = np.zeros(len(tau_list));\n",
    "    \n",
    "    for i in np.arange(len(tau_list)):\n",
    "        \n",
    "        temp_corr = np.corrcoef(L_temp, lag_X_matrix[:,i]);\n",
    "        corr_vec[i] = temp_corr[0,1]\n",
    "        \n",
    "    return [corr_vec, lag_X_matrix]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-specific",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(x, w):\n",
    "    return np.convolve(x, np.ones(w), 'valid') / w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-scroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_mat(neur_data_raw, ma_w):\n",
    "    ta_adj = ma_w-1\n",
    "    \n",
    "    temp_mov_av = np.zeros(neur_data_raw[ta_adj:,:].shape)\n",
    "    \n",
    "    for i in np.arange(neur_data_raw.shape[1]):\n",
    "        temp_mov_av[:,i] = moving_average(neur_data_raw[:,i], ma_w)\n",
    "        \n",
    "    return temp_mov_av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-yemen",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StatAnalysis(data, data_raw, neuron_ind, PO2_ch, beg_ind, end_ind, alpha, lmbda, Tw, w, ma_w, max_tau, N, lasso, tl_alpha, ffq_filter, tl):     \n",
    "    \n",
    "    ref_data = data\n",
    "    \n",
    "    if neuron_ind is None:\n",
    "        X = ref_data[beg_ind:end_ind, 3:]\n",
    "        X_raw = data_raw[beg_ind:end_ind, 3:]\n",
    "    else:\n",
    "        X = ref_data[beg_ind:end_ind, 2 + np.array(neuron_ind)]\n",
    "        X_raw = data_raw[beg_ind:end_ind, 2 + np.array(neuron_ind)]\n",
    "    \n",
    "    T = ref_data[beg_ind:end_ind, 0]\n",
    "    L = ref_data[beg_ind:end_ind, PO2_ch]\n",
    "\n",
    "    m = X.shape[1]\n",
    "    bonf_alpha = alpha/m\n",
    "\n",
    "    X_norm = (X-np.mean(X, axis = 0))/np.std(X, axis = 0)\n",
    "\n",
    "    L_strd = (L - np.mean(L))/np.std(L)\n",
    "\n",
    "    if ffq_filter:\n",
    "        L_strd = filterFreq(norm_L, [0, 1/60], 2, 1)\n",
    "    \n",
    "    tau_list = np.arange(max_tau+1)\n",
    "\n",
    "    time_window_mat_X_orig, t_vec = createTimeWindows(X, Tw, w)\n",
    "    time_window_mat_L_orig, _ = createTimeWindows(L_strd, Tw, w)\n",
    "\n",
    "    time_window_mat_X_raw, _ = createTimeWindows(X_raw, Tw, w)\n",
    "\n",
    "    num_time_windows = time_window_mat_X_orig.shape[2]\n",
    "\n",
    "    sync_ind_vec = np.zeros((m, num_time_windows))\n",
    "    PI_mat_vec = np.zeros((m,m, num_time_windows))\n",
    "    score_vec = np.zeros(num_time_windows)\n",
    "    coef_mat = np.zeros((m, num_time_windows))\n",
    "\n",
    "    time_lag_corr_mat = np.zeros((len(tau_list), m, num_time_windows));\n",
    "    sig_tl_corr_mat = np.zeros((m,num_time_windows))\n",
    "\n",
    "    for t in np.arange(num_time_windows):\n",
    "        \n",
    "        data_tw_filt_X_orig = time_window_mat_X_orig[:,:,t]\n",
    "        data_tw_filt_L_orig = time_window_mat_L_orig[:,:,t]\n",
    "\n",
    "        data_tw_filt_X_raw = time_window_mat_X_raw[:,:,t]\n",
    "        \n",
    "        X_norm_temp_orig = (data_tw_filt_X_orig - np.mean(data_tw_filt_X_orig, axis = 0))/np.std(data_tw_filt_X_orig, axis = 0)\n",
    "        L_norm_temp_orig = (data_tw_filt_L_orig - np.mean(data_tw_filt_L_orig, axis = 0))/np.std(data_tw_filt_L_orig, axis = 0)\n",
    "\n",
    "        X_norm_temp_raw = (data_tw_filt_X_raw - np.mean(data_tw_filt_X_raw, axis = 0))/np.std(data_tw_filt_X_raw, axis = 0)\n",
    "\n",
    "        max_lag = np.max(tau_list);\n",
    "\n",
    "        tau_shifted_L = L_norm_temp_orig[max_lag:]\n",
    "        sig_lag_X_matrix = np.zeros((Tw-max_lag, m));\n",
    "\n",
    "        for n in np.arange(m):\n",
    "            X_series = X_norm_temp_orig[:,n];\n",
    "            temp_corrs, temp_lag_X_matrix = detCorrSigTimeLags(X_series, L_norm_temp_orig.ravel(), tau_list);\n",
    "            \n",
    "            time_lag_corr_mat[:,n,t] = temp_corrs\n",
    "            \n",
    "            if tl > 0:\n",
    "                sig_corr_ind = tl\n",
    "                sig_tl_corr_mat[n,t] = temp_corrs[tl]\n",
    "                sig_lag_X_matrix[:,n] = temp_lag_X_matrix[:,tl]\n",
    "            else:\n",
    "                sig_corr_ind = np.argmax(temp_corrs);\n",
    "                sig_tl_corr_mat[n,t] = temp_corrs[sig_corr_ind]\n",
    "                sig_lag_X_matrix[:,n] = temp_lag_X_matrix[:,sig_corr_ind]\n",
    "\n",
    "        X_p = X_norm_temp_orig.T\n",
    "\n",
    "        nan_flag = ~np.isnan(X_p[:,0])\n",
    "        ind_range = np.arange(m)\n",
    "        nan_filter_ind = ind_range[nan_flag]\n",
    "        \n",
    "        temp_corr_vec = sig_tl_corr_mat[nan_filter_ind, t]\n",
    "        neg_corr_log = temp_corr_vec < 0\n",
    "        \n",
    "        X_p_filter = X_p[nan_filter_ind, :]\n",
    "        \n",
    "        cov_mat = np.cov(X_p_filter)\n",
    "    \n",
    "        eig_values, eig_vecs = np.linalg.eig(cov_mat)\n",
    "\n",
    "        sort_ind = np.argsort(eig_values)\n",
    "        sorted_eig_values = eig_values[sort_ind]\n",
    "        sorted_eig_vecs = eig_vecs[:,sort_ind]\n",
    "        \n",
    "        smooth = [1,6]\n",
    "        \n",
    "        X_norm_temp_raw_filtered = X_norm_temp_raw[:, nan_filter_ind]\n",
    "        \n",
    "        sync_ind, PI_mat, mean_lambdas_surr, thresh = CMA_Sync(X_norm_temp_raw_filtered, \n",
    "                                                               N, sorted_eig_values,  \n",
    "                                                               sorted_eig_vecs, bonf_alpha, smooth)\n",
    "        \n",
    "        if np.sum(~nan_flag) > 0:\n",
    "            \n",
    "            nan_indices = ind_range[~nan_flag]\n",
    "            \n",
    "            for a in nan_indices:\n",
    "                PI_mat = np.insert(PI_mat, a, 0, axis = 0)\n",
    "                PI_mat = np.insert(PI_mat, a, 0, axis = 1)\n",
    "        \n",
    "        sync_ind_vec[:np.sum(nan_flag),t] = sync_ind\n",
    "        PI_mat_vec[:,:,t] = PI_mat\n",
    "        \n",
    "        sig_lag_X_matrix_filtered = sig_lag_X_matrix[:, nan_filter_ind]\n",
    "        \n",
    "        const_vec = np.ones((sig_lag_X_matrix_filtered.shape[0],1))\n",
    "        indep_X = np.concatenate((const_vec, sig_lag_X_matrix_filtered), axis = 1)\n",
    "        \n",
    "        if lasso:\n",
    "            temp_clf = linear_model.Lasso(alpha=lmbda)\n",
    "            temp_clf.fit(indep_X, tau_shifted_L)\n",
    "\n",
    "            temp_score = temp_clf.score(indep_X, tau_shifted_L)\n",
    "            temp_coef = temp_clf.coef_\n",
    "        else:\n",
    "            model = sm.OLS(tau_shifted_L, indep_X, axis=1)\n",
    "            res = model.fit()\n",
    "\n",
    "            temp_score = res.rsquared\n",
    "            temp_coef = res.params\n",
    "\n",
    "        score_vec[t] = np.power(temp_score,1/2)\n",
    "        coef_mat[nan_filter_ind,t] = temp_coef[1:]\n",
    "    \n",
    "    corr_time_lag_vecs = np.zeros((m, num_time_windows))\n",
    "    for i in np.arange(num_time_windows):\n",
    "        for t in np.arange(m):\n",
    "            sig_ind_vec = time_lag_corr_mat[:,t,i]\n",
    "            if np.max(abs(sig_ind_vec)) < tl_alpha:\n",
    "                corr_time_lag_vecs[t,i] = float('nan');\n",
    "            else:\n",
    "                corr_time_lag_vecs[t,i] = np.argmax(sig_ind_vec)/2\n",
    "                \n",
    "    adj_time_vec = (t_vec-Tw/2)/(2*60)\n",
    "    \n",
    "    return [score_vec, coef_mat, sync_ind_vec, PI_mat_vec, adj_time_vec, sig_tl_corr_mat, corr_time_lag_vecs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterFreq(series, filter_window, samp_freq, exclude):\n",
    "    N = len(series)\n",
    "\n",
    "    # sample spacing\n",
    "    T = samp_freq\n",
    "    dt = (1/T)*samp_freq\n",
    "\n",
    "    x = np.linspace(0.0, N*T, N)\n",
    "    yf = rfft(series)\n",
    "    \n",
    "    if N % 2 == 0:\n",
    "        xf = np.linspace(0.0, dt, N//2)\n",
    "        xf_filter_temp = ((xf > filter_window[0]) & (xf <= filter_window[1]))\n",
    "        xf_filter = np.concatenate((xf_filter_temp, np.flip(xf_filter_temp)))\n",
    "    else:\n",
    "        xf = np.linspace(0.0, dt, N//2+1)\n",
    "        xf_filter_temp = ((xf > filter_window[0]) & (xf <= filter_window[1]))\n",
    "        xf_filter = np.concatenate((xf_filter_temp, np.flip(xf_filter_temp[:-1])))\n",
    "    \n",
    "    if exclude:\n",
    "        yf[xf_filter] = 0\n",
    "    else:\n",
    "        yf[~xf_filter] = 0\n",
    "\n",
    "    yf_inv = irfft(yf)\n",
    "    \n",
    "    return yf_inv    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-sterling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_sync(PI_mat, sync_ind, sig_tl_corr_mat, thresh):\n",
    "    \n",
    "    m = PI_mat.shape[0]\n",
    "    T = PI_mat.shape[2]\n",
    "    sample_m = PI_mat.shape[1]\n",
    "    \n",
    "    new_sync_ind = np.zeros((m,T))\n",
    "    \n",
    "    for i in np.arange(m):\n",
    "        for t in np.arange(T):\n",
    "            if np.sum(PI_mat[i,:,t] > thresh) == sample_m:\n",
    "                if np.sum(sig_tl_corr_mat[:,t] > thresh) == sample_m:\n",
    "                    new_sync_ind[i,t] = sync_ind[-(i+1),t]\n",
    "    \n",
    "    return new_sync_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-notification",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(X):\n",
    "    norm_X = (X - np.mean(X, axis=0))/np.std(X, axis=0)\n",
    "    return norm_X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "further-aviation",
   "metadata": {},
   "source": [
    "Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sapphire-thanks",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Individual Experiment Analysis ###\n",
    "\n",
    "## Set parameters for data analysis\n",
    "\n",
    "PO2_ch = 1       # PO2 channel (always set to 1, since there is only one channel)\n",
    "beg_ind = 0      # Beginning time index of data (in units of .5 seconds)\n",
    "end_ind = 1200   # Ending time index of data (in units of .5 seconds)\n",
    "alpha = .05      # p-value level for Bonferonni correction\n",
    "lmbda = .1       # Regularization parameter for lasso regression\n",
    "Tw = 240         # Size of time window for rolling window analysis\n",
    "w = Tw - 1       # Overlap of time windows\n",
    "ma_w = 6         # Moving average window\n",
    "max_tau = 10     # Maximum time lag for determining correlations\n",
    "N = 100          # Number of surrogates to generate for Synhronization index calculations\n",
    "lasso = 1        # Indicator variable to indicate whether to run Lasso regression. 1 = Lasso and 0 = OLS\n",
    "tl_alpha = 0     # Minimum threshold correlation threshold to record the time lag. Always set to zero.\n",
    "ffq_filter = 0   # Indicator on whether to apply smoothing in the freqyency domain (for this paper, always zero) \n",
    "tl = -1          # Amount of time lag set for ALL neurons. tl = -1 applies the usual case-by-case peak picking algorithm for choosing time lags.\n",
    "\n",
    "# Set neurons to be analysed as a list object.\n",
    "# None = All neurons in data\n",
    "neuron_inds = None \n",
    "\n",
    "synch = 0        # Parameter solely for naming figure outputs. Synch = 1 if selected neuron inds are synchronized\n",
    "\n",
    "## Insert path for SU data\n",
    "smooth_path = '[Folder path here]'\n",
    "\n",
    "## Insert SU file name\n",
    "temp_file = '[File name here]'\n",
    "\n",
    "temp_smooth_path = join(smooth_path, temp_file)\n",
    "temp_data_smooth = np.genfromtxt(temp_smooth_path, delimiter = ',')\n",
    "\n",
    "## Raw data is only used to generate surrogates for the synchronization index calculations.\n",
    "## For the purposes of this paper, we set raw data equal to smoothed data.\n",
    "temp_raw_path = join(smooth_path, temp_file)\n",
    "temp_data_raw = np.genfromtxt(temp_raw_path, delimiter = ',')\n",
    "\n",
    "time_vec = temp_data_smooth[:,0]\n",
    "L = temp_data_smooth[:, PO2_ch]\n",
    "norm_L = (L - np.mean(L))/np.std(L)\n",
    "temp_norm_L = nvf.filterFreq(norm_L, [0,2/60], 2, 1)\n",
    "\n",
    "score_vec, coef_mat, sync_ind_vec, PI_mat_vec, adj_time_vec, sig_tl_corr_mat, corr_time_lag_vecs \\\n",
    "        = StatAnalysis(temp_data_smooth, temp_data_raw, neuron_inds, PO2_ch, beg_ind, end_ind, alpha, \n",
    "                       lmbda, Tw, w, ma_w, max_tau, N, lasso, tl_alpha, ffq_filter, tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-sustainability",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = coef_mat.shape[0]\n",
    "\n",
    "sig_thresh = .5\n",
    "cluster_ind = 0\n",
    "\n",
    "test_sync = true_sync(PI_mat_vec, sync_ind_vec, sig_tl_corr_mat, -1)\n",
    "\n",
    "output_data = 1\n",
    "\n",
    "exp_name = temp_file[:-20]\n",
    "\n",
    "viridis = cm.get_cmap('viridis', 256)\n",
    "seismic = cm.get_cmap('seismic', 256)\n",
    "\n",
    "fig, axes = plt.subplots(6, 1, figsize=(15, 15))\n",
    "\n",
    "axes[0].plot(adj_time_vec, score_vec)\n",
    "axes[1].plot(adj_time_vec, test_sync[cluster_ind,:])\n",
    "axes[2].pcolormesh(PI_mat_vec[cluster_ind,:,:], cmap = viridis, rasterized=True, vmin=0, vmax=1)\n",
    "axes[3].pcolormesh(sig_tl_corr_mat, cmap = seismic, rasterized=True, vmin=-1, vmax=1)\n",
    "axes[4].pcolormesh(coef_mat, cmap = seismic, rasterized=True, vmin=-1, vmax=1)\n",
    "\n",
    "ma_w_tl = 9\n",
    "ta_adj = ma_w_tl - 1\n",
    "\n",
    "smooth_tl_ind = smooth_mat(corr_time_lag_vecs.T, ma_w_tl)\n",
    "smooth_tl_ind = smooth_tl_ind.T\n",
    "\n",
    "shifted_adj_time_vec = adj_time_vec[ta_adj:]\n",
    "\n",
    "for i in np.arange(m):\n",
    "    axes[5].plot(shifted_adj_time_vec, smooth_tl_ind[i,:], \\\n",
    "                 label = \"Neuron \" + str(i+1))\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "if output_data:\n",
    "    \n",
    "    if neuron_inds == None:\n",
    "        out_cases_folder = '/home/evan/Projects/NeuronVasomotion/Synchronization_Analysis/' + exp_name + '_fullpop'\n",
    "    elif synch == 0:\n",
    "        out_cases_folder = '/home/evan/Projects/NeuronVasomotion/Synchronization_Analysis/' + exp_name + '_subpop_nonsynch'\n",
    "    else:\n",
    "        out_cases_folder = '/home/evan/Projects/NeuronVasomotion/Synchronization_Analysis/' + exp_name + '_subpop'\n",
    "    \n",
    "    if not(os.path.exists(out_cases_folder)):\n",
    "        os.makedirs(out_cases_folder)\n",
    "    \n",
    "    if neuron_inds == None:\n",
    "        fig.savefig(join(out_cases_folder, exp_name + \"_fig_fullpop.png\"));\n",
    "    elif synch == 0:\n",
    "        fig.savefig(join(out_cases_folder, exp_name + \"_fig_subpop_nonsynch.png\"));\n",
    "    else:\n",
    "        fig.savefig(join(out_cases_folder, exp_name + \"_fig_subpop.png\"));\n",
    "    \n",
    "    mat_output = np.c_[adj_time_vec, score_vec, test_sync[0,:].reshape(-1,1)]\n",
    "    \n",
    "    if neuron_inds == None:\n",
    "        neuron_inds_temp = np.arange(1, temp_data_smooth.shape[1]-2)\n",
    "    else:\n",
    "        neuron_inds_temp = neuron_inds\n",
    "        \n",
    "    neuron_data = temp_data_smooth[:,2+np.array(neuron_inds_temp)]\n",
    "    \n",
    "    data_output = np.c_[time_vec, norm_L, neuron_data]\n",
    "    \n",
    "    h1 = \"Time (min), Score (r), Synchronization Index\"\n",
    "    np.savetxt(join(out_cases_folder, exp_name + \"_fig_data.csv\"), mat_output, delimiter = ',', header = h1, comments='')\n",
    "    \n",
    "    # Create second header\n",
    "    for i in np.arange(neuron_data.shape[1]):\n",
    "        if i == 0:\n",
    "            h2 = \"SU\" + str(neuron_inds_temp[i])\n",
    "        else:\n",
    "            h2 += \", SU\" + str(neuron_inds_temp[i])\n",
    "    \n",
    "    h3 = \"Time (s), PO2, \" + h2\n",
    "    \n",
    "    np.savetxt(join(out_cases_folder, exp_name + \"_timelag.csv\"), smooth_tl_ind.T, delimiter = ',', header = h2, comments='')\n",
    "    np.savetxt(join(out_cases_folder, exp_name + \"_neuron_series.csv\"), data_output, delimiter = ',', header = h3, comments='')\n",
    "    np.savetxt(join(out_cases_folder, exp_name + \"_corr_mat.csv\"), sig_tl_corr_mat.T, delimiter = ',', header = h2, comments='')\n",
    "    np.savetxt(join(out_cases_folder, exp_name + \"_coef_mat.csv\"), coef_mat.T, delimiter = ',', header = h2, comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "directed-minnesota",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 1, figsize=(15, 5))\n",
    "\n",
    "if neuron_inds == None:\n",
    "    neuron_inds_temp = np.arange(1, temp_data_smooth.shape[1]-2)\n",
    "else:\n",
    "    neuron_inds_temp = neuron_inds\n",
    "\n",
    "neuron_data = temp_data_smooth[:,2+np.array(neuron_inds_temp)]\n",
    "\n",
    "num_neurons = neuron_data.shape[1]\n",
    "max_ind = np.argmax(score_vec)\n",
    "tl_vec = corr_time_lag_vecs[:, max_ind]\n",
    "\n",
    "max_tau = 10\n",
    "Tw = 250\n",
    "\n",
    "beg_ind = max_ind\n",
    "end_ind = max_ind + Tw\n",
    "\n",
    "neur_num = 0\n",
    "tl = int(tl_vec[neur_num])\n",
    "\n",
    "mod_time_vec = time_vec[beg_ind+max_tau:end_ind]\n",
    "\n",
    "window_L = norm_L[beg_ind:end_ind]\n",
    "window_L = norm(window_L)\n",
    "\n",
    "tw_norm_L = window_L[max_tau:]\n",
    "\n",
    "normed_neuron_data = norm(neuron_data[beg_ind:end_ind])\n",
    "\n",
    "tl_neuron_data = np.zeros((end_ind-beg_ind-max_tau, num_neurons))\n",
    "\n",
    "for i in np.arange(num_neurons):\n",
    "    temp_tl = int(tl_vec[i]*2)\n",
    "    tl_neuron_data[:, i] = normed_neuron_data[max_tau-temp_tl:Tw-temp_tl,i]\n",
    "\n",
    "axes.plot(mod_time_vec, tw_norm_L)\n",
    "\n",
    "axes.plot(mod_time_vec, tl_neuron_data[:,neur_num])\n",
    "\n",
    "const_vec = np.ones((tl_neuron_data.shape[0],1))\n",
    "indep_X = np.concatenate((const_vec, tl_neuron_data), axis = 1)\n",
    "\n",
    "temp_clf = linear_model.Lasso(alpha=.1)\n",
    "temp_clf.fit(indep_X , tw_norm_L)\n",
    "temp_score = temp_clf.score(indep_X, tw_norm_L)\n",
    "temp_coef = temp_clf.coef_\n",
    "\n",
    "print(temp_coef)\n",
    "print(np.power(temp_score, 1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "OLS_series = temp_clf.predict(indep_X)\n",
    "normed_OLS_series = norm(OLS_series)\n",
    "\n",
    "plt.plot(tw_norm_L)\n",
    "plt.plot(normed_OLS_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "married-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mat = np.concatenate((mod_time_vec.reshape(-1,1),tw_norm_L.reshape(-1,1),\n",
    "                             tl_neuron_data, normed_OLS_series.reshape(-1,1), ), axis=1)\n",
    "    \n",
    "if not(os.path.exists(out_cases_folder)):\n",
    "    os.makedirs(out_cases_folder)\n",
    "\n",
    "output_path = join(out_cases_folder, exp_name + \"_MaxTWData.csv\")\n",
    "\n",
    "import csv\n",
    "\n",
    "with open(output_path,'w') as result_file:\n",
    "    wr = csv.writer(result_file, dialect='excel')\n",
    "\n",
    "    header = [\"Time\", \"PO2\"]\n",
    "    \n",
    "    for h in np.arange(num_neurons):\n",
    "        temp_SU = \"SU\" + str(neuron_inds_temp[h])\n",
    "        header.append(temp_SU)\n",
    "        \n",
    "    header.append(\"Regression Output\")\n",
    "    \n",
    "    wr.writerow(header)\n",
    "\n",
    "    for i in np.arange(output_mat.shape[0]):\n",
    "        wr.writerow(output_mat[i,:])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
